:chapterNumber: B
:chapterId: appendix-b
:sectnums:
:nodeCurrentVersion: v8
:npmCurrentVersion: v5
:revdate: {docdate}
:sourceDir: ./examples
:imagesdir: {indir}
ifdef::env[]
:imagesdir: .
endif::[]

[appendix]
= Design Patterns

TBD.

====
.Sommaire
- TBD.
====

[abstract]
--
Certains concepts de programmation sont utiles à connaître pour écrire un code plus concis, mieux organisé et davantage consistant.

Ils vous permettront de mieux comprendre la différence entre du code bloquant et non-bloquant, asynchrone et synchrone et comment organiser votre code de manière robuste tout en apprenant à réagir aux erreurs.
--

include::../resources/tip-versions.adoc[]
include::../resources/tip-examples.adoc[]

toc::[]

== Code synchrone et asynchrone

Certains langages et la programmation DOM nous ont déjà habitué à gérer du code de manière asynchrone.
De manière générale, la différence réside dans l'accès au(x) résultat(s) de nos différentes invocations.

L'exemple suivant est une démonstration de code synchrone :

[source,javascript]
----
const date = Date.now();
----

En effet, le résultat est retourné _immédiatement_ à la suite de l'invocation de la fonction.
La notion d'_immédiateté_ correspond en réalité à un temps variable — dans le cas de cette fonction, à quelques nano-secondes.

Maintenant tentons de lire de manière asynchrone le contenu d'un fichier :

[source,javascript]
.async.js
----
include::{sourceDir}/async.js[]
----

Puisque la méthode `readFile` ne retourne pas de résultat dans le même cycle d'_Event loop_, il faut bien que le résultat soit transmis d'une manière ou d'une autre.

Le design pattern _callback_ est employé pour retourner le résultat et le cas échéant, une erreur.
Ce design pattern est expliqué plus en détail dans une section suivante de ce même chapitre.

Si ce code est tout à fait fonctionnel, il présente quelques inconvénients :

- il n'est pas réutilisable ;
- il est difficile de discerner _où_ manipuler le résultat attendu au premier abord ;
- où intercepter les erreurs ? Et qu'en faire ?

Ces problèmes seront amplifiés à mesure que la complexité de votre code et la profondeur des _callbacks_ augmentera.

Tentons une approche plus modulaire, toujours asynchrone :

[source,javascript]
.async-reusable.js
----
include::{sourceDir}/async-reusable.js[]
----

La séparation entre succès et échec est désormais évidente.
Le code est également plus lisible.
Son abstraction en module indépendant le rend réutilisable à tout niveau dans l'application — et testable par la même occasion :

[source,javascript]
.filecontent/index.js
----
include::{sourceDir}/filecontent/index.js[]
----

Voyons à quoi ressemblerait ce code s'il était synchrone :

[source,javascript]
.sync.js
----
include::{sourceDir}/sync.js[]
----

Finalement le code n'est pas nécessairement plus clair.
On doit activement essayer de faire la distinction entre un résultat d'une valeur _fausse_ et un résultat issu d'une erreur (système surchargé, fichier inexistant, lecture interrompue, _timeout_ etc.).

Le module d'accès synchrone au contenu d'un fichier ressemblerait à ceci :

[source,javascript]
.filecontent/sync.js
----
include::{sourceDir}/filecontent/sync.js[]
----

Il y a légèrement moins de lignes et le gain de lisibilité n'est pas flagrant.

Et d'ailleurs, puisque Node fournit des méthodes synchrones équivalentes au méthodes asynchrones, pourquoi s'embêter ? +
Parce que l'asynchronicité est le seul moyen de ne pas bloquer le processus en délégant à l'_Event loop_ la responsabilité d'exécuter le _callback_, plus tard.

*Node nous procure en réalité une API non-bloquante*.

== Code bloquant et non-bloquant

Node est fréquemment acclamé pour son API asynchrone.
Toutefois le facteur le plus important est son caractère non-bloquant.
Mais alors, *quelle différence entre code asynchrone et code non-bloquant* ?

Considérons le code suivant :

[source,javascript]
.async-fake.js
----
include::{sourceDir}/async-fake.js[]
----

Il ressemble en tout point à un de nos exemples précédent de code _non-bloquant_.
Pourtant il est bloquant car le code sur lequel il repose propose certes un mécanisme de _callback_, mais exécuté dans le même cycle d'_Event loop_ :

[source,javascript]
.filecontent/async-fake.js
----
include::{sourceDir}/filecontent/async-fake.js[]
----
<1> Cette interface de fonction suggère une fonction _asynchrone_…
<2> … tandis que cette ligne est en réalité *bloquante*.

Le fait que Node explicite tout accès bloquant permet de repérer facilement ces goulots d'étrangement.

Que se passe-t'il du côté de Node si le code exécuté est :

- *bloquant* : aucune instruction n'est traité, on _attend_ ;
- *non-bloquant* : le reste des instructions du même cycle d'_Event loop_ est traité et ainsi de suite.

En clair, on n'exécute pas du code non-bloquant parce que c'est davantage à la mode : on exécute du code non-bloquant pour économiser du temps et traiter davantage d'instructions. +
Par effet mécanique, à puissance CPU équivalente, un code non-bloquant pourra traiter davantage d'instructions à la seconde car il gâchera moins de temps à attendre un retour d'instruction.

Ne vous fiez pas nécessairement à l'API mise à disposition par les modules employés mais vérifiez bien qu'elles emploient un minimum d'instructions bloquantes. +
Un seul module bloquant et peu performant peut réduire à néant les performances de vos applications.

== index.js

Il arrive que la modularisation de votre code nécessite l'utilisation de multiples appels à `require()` pour charger l'intégralité des modules nécessaires.

Ce n'est pas un signe de mauvais code mais on peut sentir une certaine répétition dans l'exemple suivant :

[source,javascript]
----
const Person = require('./lib/models/person.js');
const Vehicle = require('./lib/models/vehicle.js');
const Location = require('./lib/models/location.js');
const Transaction = require('./lib/models/transaction.js');

const rental = new Transaction({
  // ...
});

rental.save((err, commit) => {
  if (err) {
    throw err;
	}

  // ...
});
----

Nous pourrions grouper les appels aux modèles car ils appartiennent à un même domaine.
L'exemple précédent se résumerait alors à ceci :

[source,javascript]
----
const models = require('./lib/models');

const rental = new models.Transaction({
  // ...
});
----

Lorsque le chemin indiqué en paramètre de la fonction `require()` est un répertoire, l'heuristique veut que Node vérifie l'existence d'un fichier `index.js` et le charge le cas échéant.

Ainsi, `require('./lib/models')` est équivalent à `require('./lib/models/index.js')`.

Le fichier `index.js` est quant à lui une factorisation des appels précédents :

[source,javascript]
.lib/models/index.js
----
'use strict';

module.exports = {
  Person: require('./person.js'),
  Location: require('./location.js'),
  Vehicle: require('./vehicle.js'),
  Transaction: require('./transaction.js')
};
----

Ce _pattern_ est utile pour réduire l'encombrement visuel et regrouper des modules par logique applicative.

== Globbing

Le _globbing_ est un _pattern_ fréquemment employé dans le monde UNIX.
Au lieu de nommer des fichiers un par un, le mécanisme permet de désigner des motifs de sélection, de profondeur de recherche et d'exclusion.

Les motifs utilisables sont les suivants :

- `*` : n'importe quelle chaîne de caractères ;
- `**` : n'importe quel répertoire ;
- `{js,json,adoc}` : la chaîne `js`, `json` ou `adoc` ;
- `[adoc]` : un caractère dans l'ensemble `a`, `d`, `o` et `c` ;
- `!(adoc)` : sauf la chaîne _js_.

Parcourir et filtrer le contenu d'un répertoire devient un jeu d'enfant — bien plus que s'il avait fallu utiliser soi-même l'API Node `fs` à coup de `readDir` récursif.

Au final, c'est ce qui est effectué mais sans que nous ayons à écrire ce code nous-même.

[source,javascript]
.glob.js
----
include::{sourceDir}/glob.js[]
----
<1> fichiers débutant par `package` ;
<2> fichiers débutant par `index` et suffixés par `adoc` ou une chaîne qui débute par `js` ;
<3> fichiers débutant par `index` et dont le suffixe est précédé par les lettres `a` ou `s` ;
<4> fichiers débutant par `index`, à l'exception de `index.js` ;
<5> fichiers suffixés par `js` contenus dans le répertoire `{sourceDir}` et tous ses sous-répertoires.

[CAUTION]
.[RemarquePreTitre]#Attention# Certains modules sont bloquants
====
Certains modules de _globbing_ sont bloquants, comme `globule@~0.2.0`.

Méfiez-vous donc de leur API séduisante car leur performance s'en trouvera amoindrie.
====

== Littéraux de modèle avec étiquette (_tagged template literals_)

Les _template literals_ peuvent se préfixer d'un nom de fonction.
Ce mécanisme nommé _tagged template literals_ sert de filtre pour interpréter et interpoler le contenu de chaque _template_ (élément contenu dans `${}`). Vous pouvez écrire vos propres fonctions mais aussi utiliser des modules _npm_. +
L'exemple suivant illustre une sécurisation de contenu tiers à l'aide de la fonction `safeHtml` fournie par le module `common-tags` ([URL]#https://npmjs.com/common-tags#) :

[source%interactive,javascript]
.literal-tags.js
----
include::{sourceDir}/tagged-literals.js[]
----
<1> Affiche `<div class="user-content">\n<script>alert(document.cookie)</script>\n</div>` ;
<2> Affiche `<div class="user-content">\n\&lt;script\&gt;alert(document.cookie)\&lt;/script\&gt;\n</div>`.

mdn::reference[Template_literals, title="Littéraux de modèle"]

== Injection de module

Il est tentant de créer des modules pour abstraire certaines parties de votre logique applicative.
C'est d'autant plus pertinent si vous souhaitez partager ce code au sein d'un même projet ou entre plusieurs projets similaires.

L'exemple suivant illustre la volonté de déporter la configuration d'une hypothétique application dans un module nommé `app-configure.js` :

[source,javascript]
.app.js
----
const app = module.exports = new AppServer();

require('./app-configure.js');
----

Ce module de configuration requiert à son tour l'application pour en configurer l'objet exporté :

[source,javascript]
.app-configure.js
----
const app = require('./app.js');
const ejsEngine = require('consolidate').ejs;

app.set('X-Powered-By', 'ACME Corp.');
app.set('view engine', ejsEngine);

// ...
----

Cette approche pose toutefois deux problèmes :

- l'inclusion cyclique — même si Node s'en sortira, on pressent une erreur de _design_ ;
- quid de l'utilisation de ce module de configuration si l'on souhaite configurer un autre fichier que `app.js` ?

L'injection de variable est un _pattern_ intéressant car il résout ce dilemme sans présenter d'inconvénient :

[source,javascript]
.app-reworked.js
----
const app = new App();

require('./app-configure-reworked.js')(app);
----

Le module de configuration devient alors une fonction recevant l'objet applicatif en paramètre :

[source,javascript]
.app-configure-reworked.js
----
const ejsEngine = require('consolidate').ejs;

module.exports = function(app){
  app.set('X-Powered-By', 'ACME Corp.');
  app.set('view engine', ejsEngine);

  // ...
};
----

Ce _pattern_ est intéressant à plus d'un titre :

- il rend explicite toute dépendance ;
- le module d'injection peut baser son comportement sur l'état des objets passés en paramètre ;
- il n'impose qu'une seule chose : respecter la signature de la fonction d'injection.

[[pattern-callback]]
== Callback

Le _pattern_ _callback_ est très couramment employé et pour cause : il est systématiquement employé dans les API asynchrones de Node. Par exemple, pour lire un fichier :

[source,javascript]
----
'use strict';

const fs = require('fs');

fs.readFile('path/to/file', callback(err, fileContent) {
  if (err) { // <1>
    // ...
  }
});
----
<1> `err` est généralement une instance de `Error`, sinon la variable est égale à `undefined` ou `null`.

Le _pattern_ implique une fonction ayant un ou plusieurs arguments ; le premier d'entre eux étant par convention un objet d'erreur. +
Ce mécanisme permet de *signaler une erreur* ou un *résultat* de manière asynchrone.
Cependant on se rend vite compte que la simplicité du _pattern_ cache une complexité dans la gestion des erreurs.
Comment les déclarer ?
Comment les intercepter ?
Comment les propager ailleurs dans notre application ?

Forçons le trait en créant une fonction asynchrone (`messageAbbr`) faisant appel à trois autres fonctions asynchrones (`uppercaseAsync`, `splitWordsAsync` et `abbreviateAsync`) :

[source,javascript]
.message-abbr/index.js
----
include::{sourceDir}/message-abbr/index.js[]
----

Plusieurs remarques :

- `process.nextTick` est utilisé pour déporter l'exécution du process principal vers l'_Event Loop_ ;
- chaque niveau de _callback_ appellera la fonction de callback initiale avec l'objet d'erreur en premier argument ;
- on constate que l'imbrication des fonctions rend difficilement contrôlable la possibilité d'interagir avant que l'intégralité de la chaîne soit accomplie.

L'exemple suivant repose sur les fonctions précédemment listées de `message-abbr/index.js`.
La fonction `messageAbbr` est exécutée de trois manières différentes pour souligner plusieurs cas de figure :

[source,javascript]
.callback.js
----
include::{sourceDir}/callback.js[]
----
<1> _Premier appel_ : affiche la chaîne `GME` ;
<2> _Deuxième appel_ : affiche le message d'erreur `[TypeError: message is not a String]` ;
<3> _Troisième appel_ : affiche une exception `TypeError: Cannot read property 'toLocaleUpperCase' of null` et termine le script de manière prématurée.

Le premier appel à `messageAbbr` se déroule dans des conditions optimales.
La fonction de callback transmet un premier paramètre `err` équivalent à `null` et une valeur conforme aux attentes.

Le deuxième appel illustre une interception maîtrisée d'un cas d'erreur.
C'est bien `console.error(err)` qui sera interprété suite à une erreur renvoyée par la fonction `splitWordsAsync`.

Le troisième et dernier appel interpelle : pourquoi le bloc `try/catch` est-il resté sans effet ?
Pour la simple et bonne raison que `try/catch` ne fonctionne que sur du _code synchrone_. +
L'exception n'étant pas interceptée par notre code, elle continue de remonter jusqu'au processus initial qui émet un événement `uncaughtException`, processus qui se terminera avec un code d'erreur si aucune fonction n'écoute ce dit événement `uncaughtException`.

Autrement dit, un code asynchrone basé sur des _callbacks_ requiert beaucoup de précautions du fait du crash potentiel de l'application si une erreur n'est pas interceptée.

Enfin, on notera que l'ordre d'affichage des deux premiers appels n'est pas nécessairement le même que l'ordre d'exécution.

Le code initial peut être rendu légèrement plus lisible sans toucher à l'API de callback en utilisant la méthode `waterfall` de la librairie `async` ([URL]#https://npmjs.com/async#) :

[source,javascript]
.message-abbr/waterfall.js
----
include::{sourceDir}/message-abbr/waterfall.js[]
----

Le mécanisme `waterfall` exécute chaque callback de manière séquentielle, en transmettant l'erreur et le résultat au callback suivant.

[CAUTION]
.[RemarquePreTitre]#Performance# Non-bloquant mais pas rapide pour autant
====
Vous aurez beau rendre non-bloquant la majorité de votre code, il n'en sera pas nécessairement exécuté plus rapidement.

Certes votre application pourra _accepter_ davantage de sollicitation mais votre code, lui, ira à la vitesse induite par l'enchainement logique du flux de données.

Le temps d'exécution des callbacks correspond à la _somme du temps d'exécution de chaque callback_. +
Un excellent moyen pour gérer du code _asynchrone_ et _parallèle_ est le _pattern_ _promesse_, abordé dans les pages suivantes.
====

== Event

Les _callbacks_ nous permettent d'agir lorsqu'une exécution asynchrone est en mesure de nous retourner un résultat ou une erreur. +
Leur fonctionnement est toutefois encapsulé et limité à la portée de la portion de code dans laquelle nous pouvons insérer des instructions.
Difficile donc d'exposer notre logique applicative en dehors de ces _callbacks_.

Les événements nous offrent un tel mécanisme d'exposition, en permettant la connexion de plusieurs écouteurs (_listeners_).
Plusieurs composants indépendants peuvent alors utiliser les résultats pour leurs propres besoins.

Il s'agit d'un _pattern_ particulièrement intéressant pour adresser ces besoins :

- gérer des cas de figure ayant trait à une progression ;
- gérer des cas de figure plus complexes qu'une logique binaire de réussite ou d'échec ;
- séparer la logique d'exécution d'un résultat unique (éviter de mettre tous les _callbacks_ dans le même panier dirait-on…);
- transmettre des résultats au travers de plusieurs couches applicatives (un émetteur, plusieurs récepteurs).

Dans l'exemple suivant, nous allons réutiliser la fonction `messageAbbr` développée dans la précédente section _callbacks_.
Cette fois-ci, nous allons exécuter des _opérations synchrones et asynchrones_ en _callback_ de la fonction `messageAbbr` :

[source,javascript]
.callback-naive.js
----
include::{sourceDir}/callback-naive.js[]
----

Les fonctions `logData`, `logPerformance` et `storeData` sont exécutées en cas de succès du _callback_ de `messageAbbr`. +
Mais que se passe-t-il si une de ces trois fonctions génère une erreur ? Et si l'une d'entre elles s'exécute de manière asynchrone ? Comment faire remonter l'erreur en dehors de `messageAbbr` ?

Retravaillons le précédent exemple pour explorer une approche événementielle :

[source,javascript]
.event.js
----
include::{sourceDir}/event.js[]
----
<1> L'utilisation de `module.exports` permet d'exposer l'émetteur d'événement à d'autres modules, par exemple `require('./events').on('data', ...)`.

La fonction `messageAbbr` retourne désormais une instance de l'objet `EventEmitter` de manière synchrone.
Des écouteurs sont branchés sur l'objet retourné et sont exécutés de manière asynchrone, lorsque leur événement respectif est émis.

Observons maintenant le code source modifié de `messageAbbr` ayant permis d'exposer cette interface événementielle :

[source,javascript]
.message-abbr/evented.js
----
include::{sourceDir}/message-abbr/evented.js[]
----

Le seul changement se situe dans la fonction `messageAbbr` : elle retourne désormais un objet `EventEmitter`.
Cet objet est interfacé dans les moments critiques de la fonction `waterfall` et en relaie son cycle de vie _en dehors_ de la fonction `messageAbbr`. +
À noter que le nommage des événements est libre.
Certains noms sont utilisés de manière conventionnelle pour identifier des actions – par exemple, `error`, `data`, `end` etc.

[TIP]
.[RemarquePreTitre]#Astuce# `emitter.setMaxListeners`
====
Vous pouvez brancher dix écouteurs maximum sur un émetteur.
C'est en général un nombre suffisant mais cette limite peut être augmentée (ou réduite) si le besoin se fait sentir.

[source,javascript]
----
include::{sourceDir}/events-setmaxlisteners.js[]
----
====

Il est important de bien connaître et de bien comprendre ce _pattern_ car il est fréquemment employé au sein des API natives de Node et dans de nombreux modules npm.

[[promise]]
== Promesses

Le concept des promesses est extrêmement puissant pour gérer, ordonner et organiser un ou plusieurs enchaînements d'exécutions asynchrones.

Il y a plusieurs enjeux dans l'organisation du code liés aux promesses :

- intercepter les *erreurs* ;
- intégrer du code *à base de _callbacks_* ;
- *intégrer du code* qui n'est pas au courant d'être dans une promesse ;
- *modulariser* son code ;
- profiter de la *parallélisation*.

Le fichier `message-abbr/index.js` exporte une fonction asynchrone dont l'argument final est un <<pattern-callback,callback>>.
Une première approche pour utiliser cette fonction _comme une promesse_ serait de l'encapsuler de la manière suivante :

[source,javascript]
.promise-callback.js
----
include::{sourceDir}/promise-callback.js[]
----

C'est minimal mais on crée un code _fragile_ : nous devons faire en sorte que les interfaces de l'encapsulation évoluent en simultané.
La réalité c'est que nous n'avons pas envie d'encapsuler toutes les fonctions asynchrones pour les intégrer dans des chaînes de promesses.

L'API native `util.promisify` permet de transformer une fonction de callback en promesse. +
L'exemple précédent serait réécrit de la manière suivante :

[source,javascript]
.promise-promisified.js
----
include::{sourceDir}/promise-promisified.js[]
----

[TIP]
.[RemarquePreTitre]#Alternatives# Des callbacks aux promesses
====
Des modules comme `bluebird` et `pify` sont capables d'étendre des objets et des modules en plus de fonctions nommées. +
Le gain ?
Transformer plusieurs fonctions en une seule ligne.

- [URL]#https://npmjs.com/bluebird#
- [URL]#https://npmjs.com/pify#
====


Explorons désormais une *gestion robuste des erreurs* : toute exception entraine la _résolution négative_ de la promesse – même si on ne fait pas appel à la fonction `reject()`.
Il est possible de gérer les erreurs finement en ayant recourt à `.catch()`.

[source,javascript]
.promise-errors.js
----
include::{sourceDir}/promise-errors.js[]
----
<1> Ce `.catch()` se déclenchera si `messageAbbr()` ou `logData()` génèrent une exception ;
<2> Génère une exception — elle ne sera pas interceptée par la fonction `logErr()` située sur la même ligne ;
<3> Ce `.catch()` affichera l'erreur générée à l'élément _précédent_ dans la chaîne de promesses ;
<4> La fonction `messageAbbr()` génère une exception, gérée par l'élément _suivant_ dans la chaîne de promesses ;
<5> La fonction `messageAbbr()` génère une exception, qui n'est pas interceptée – Node affiche un _warning_ dans la _sortie erreur_ : `UnhandledPromiseRejectionWarning: Unhandled promise rejection`.

Ce dernier cas de figure illustre une des limitations des promesses : c'est à nous de faire attention à intercepter les erreurs.
Celles-ci ne seront pas toutes remontées si un `.catch()` final n'est pas ajouté à la chaîne de promesses. +
Node affichera un message d'erreur avec une trace incomplète.

`Promise.all()` nous permet d'exécuter une fonction lorsque _toutes_ les promesses sont résolues.
Détail important cependant, _toutes_ les promesses passées en argument de `Promise.all()` sont exécutées en *parallèle* :

[source,javascript]
.promise-multiple.js
----
include::{sourceDir}/promise-multiple.js[]
----
<1> Affiche `Promesse tenue !` en premier ;
<2> Puis affiche `[ 'H&M', 'HMS', 'GO' ]`

Cette technique est plus rapide qu'un enchainement de promesses du fait de leur _exécution en parallèle_.
Le temps d'exécution total correspond à celui de la promesse la plus lente.

[TIP]
.[RemarquePreTitre]#npm# Librairies de promesses
====
Les librairies de promesses suivantes ajoutent de nouveaux comportements et des sucres syntaxiques :

- [URL]#https://npmjs.com/bluebird#
- [URL]#https://npmjs.com/when#
- [URL]#https://npmjs.com/es6-promise# (un polyfill pour d'anciennes versions de Node et des navigateurs Web peu récents)
====

== Streams

Les _streams_ représentent un concept déjà connu par les pratiquants du monde UNIX.
Nous avons déjà vu dans cette section qu'une opération asynchrone ne bloque pas le reste de l'exécution du programme.
Mais les _patterns_ précédents n'adressent pas la problématique de mémoire.

Prenons un exemple courant : télécharger un fichier distant et le stocker sur disque.

[source%interactive,javascript]
.streams-http-async.js
----
include::{sourceDir}/streams-http-async.js[]
----

Que se passe-t-il dans le précédent exemple ?

1. une requête est envoyée ;
2. la réponse arrive morceau par morceau et s'accumule en mémoire ;
3. ce _callback_ est exécuté lorsque la lecture de données est épuisée ;
4. les données sont écrites en un bloc sur le système de fichier local.

Ça fonctionne, c'est non-bloquant mais il y a deux possibles inconvénients :

1. on exécute les actions de téléchargement et d'écriture de manière séquentielle ; on accumule le temps d'attente de chaque _callback_ ;
2. l'intégralité des données doit être stockée en mémoire.

Les _streams_ servent très précisément à résoudre ces inconvénients.
Rectifions notre précédent exemple :

[source%interactive,javascript]
.streams-http.js
----
include::{sourceDir}/streams-http.js[]
----

Que se passe-t-il dans cet exemple ?

1. la requête passe un objet de type _IncomingMessage_ et qui se trouve implémenter un _ReadableStream_ ;
2. `fs.createWriteStream` retourne un _WriteableStream_ ;
3. la méthode `pipe()` déverse les données dans le _WritableStream_ ;
4. le _WritableStream_ écrit sur disque au fur et à mesure de la réception des données du _ReadableStream_ ;
5. le _ReadableStream_ termine la connexion en émettant un évènement _finish_ lorsqu'il n'y a plus de données à lire.

[TIP]
.[RemarquePreTitre]#API# Les types de _streams_
====
Node met à disposition plusieurs types de _streams_, chacun ayant sa propre vocation :

- _ReadableStream_ : données en lecture seule ;
- _WriteableStream_ : données en écriture seule ;
- _DuplexStream_ : données en lecture et écriture (connexion bi-directionnelle, opérations asymétriques etc.) ;
- _TransformStream_ : données en lecture, modifiées et émises en écriture (filtres de compression, parsing etc.) ;
- _PassThroughStream_ : données en lecture émises à l'identique en écriture (_logging_, débogage etc.).
====

Les _streams_ sont efficaces pour transférer et modifier des données de manière constante et maitrisée, le tout avec une faible empreinte mémoire.

Les opérations asynchrones à base de _callbacks_ allouent autant de mémoire que nécessaire de manière fluctuante tandis que les _streams_ ne consommeront que quelques kilo-octets de manière constante.

C'est là où réside la promesse de Node : des opérations non-bloquantes et à faible empreinte mémoire.
Il s'agit d'une combinaison gagnante si ces traitements sont multipliés et rendus simultanés en cas d'accès concurrents à l'application.

Dix accès concurrents ouvrant un fichier de 10 méga-octets nécessitera au bas mot 100 méga-octets de mémoire disponible. +
Les mêmes dix accès concurrents ouvrant ce fichier en _streaming_ nécessitera tout au plus une cinquantaine de kilo-octets de mémoire disponible.

Continuons sur notre lancée et intéressons-nous à la manipulation d'un fichier JSON.
Nous souhaitons le lire, le parser et en afficher le contenu avant de pouvoir procéder à d'autres opérations de tri ou de filtre.

Voilà comment nous procéderions avec une approche classique non-bloquante :

[source,javascript]
.streams-async.js
----
include::{sourceDir}/streams-async.js[]
----

C'est certes non-bloquant mais nous faisons face à un problème de performance lié à la montée en charge, en relation avec la taille du fichier à charger et à parser :

- `JSON.parse` doit charger l'intégralité du fichier JSON en mémoire ;
- `JSON.parse` ne faisant pas de parsing progressif, il faudra attendre que l'intégralité du fichier soit parsé pour commencer en à manipuler le résultat.

C'est peut-être acceptable dans le cas d'un simple utilitaire exécuté ponctuellement mais ce sera clairement problématique pour la montée en charge d'une application soumise à des accès concurrents : il faudra en effet multiplier la quantité de mémoire allouée par fichier par le nombre d'accès simultanés au service.

En clair, ce modèle ne fonctionnera pas si vous exposez des archives de fichiers ou même plus simplement, si vous proposez des fonctions d'export requétant et renvoyant des résultats de base de données.

Sur la base de notre premier essai avec les _streams_, transformons donc la lecture ponctuelle en lecture progressive :

[source,javascript]
.streams.js
----
include::{sourceDir}/streams.js[]
----

Que se passe-t-il lors de l'exécution de la méthode `createReadStream` :

1. Node retourne une instance d'objet `ReadableStream` de manière synchrone ;
2. vous configurez l'instance de `ReadableStream` pour choisir votre méthode de consommation de données ;
3. l'instance de `ReadableStream` émet des événements relatifs à sa progression ;
4. la consommation des données s'arrête lorsque vous le décidez ou lorsque l'instance de `ReadableStream` émet l'événement `end`.

Recyclons notre précédent exemple avec un fichier JSON plus volumineux.
Le fichier en question est issu de la _ressourcerie Datalocale_ ([URL]#https://www.datalocale.fr/drupal7/dataset/catalogue-datalocale#), en date du 19 mars 2014 :

[source,javascript]
.streams-large.js
----
include::{sourceDir}/streams-large.js[]
----
<1> Jette une exception `SyntaxError: Unexpected end of input`.

En quoi le simple changement de la source de données peut-il affecter notre script, qui fonctionnait parfaitement dans notre exemple précédent ?

Le mécanisme des _streams_ est ici mis en évidence par le volume de données contenus dans le fichier JSON (un peu plus d'un méga-octet) : seule une dizaine d'éléments ont été retournés ; le dernier étant même partiellement tronqué.

En pratique, chaque _buffer_ correspond plus ou moins à 4Ko de données… mais 4Ko de données brutes. +
La fonction `JSON.parse` devient alors inefficace car elle impose d'avoir à disposition une structure JSON finie et complète.

Il nous faudrait un parseur JSON compatible avec les _streams_ ; c'est à dire qui soit capable de parser une structure JSON au fur et à mesure de sa lecture. +
C'est exactement ce que nous propose le module npm `JSONStream` ([URL]#https://npmjs.com/JSONStream#).

Notre script se transforme légèrement et nécessite l'emploi de la méthode `pipe()` sur laquelle nous nous pencherons juste après :

[source,javascript]
.streams-jsonstream.js
----
include::{sourceDir}/streams-jsonstream.js[]
----
<1> Affiche `208`.

La fonction `JSONStream.parse()` retourne en réalité un nouveau _stream_ qui lit les données émises par `fs.createReadStream`. +
Ce nouveau _stream_ a été configuré pour retourner chaque élément (`\*`) du tableau JSON. +
Si nous avions voulu ne retourner que la propriété `resources` de chaque élément, nous aurions alors écrit `JSONStream.parse('*.resources')`.

Le mécanisme de `pipe` permet de transvaser un flux de données d'un _stream_ vers un autre.
Ce comportement est littéralement le même que l'opérateur `|` dans le monde UNIX :

[source,bash]
----
cat /etc/networks | head -n3 | grep -i 'database'
----

Cet exemple précédent pourrait être écrit de la manière suivante avec Node (les modules npm sont fictifs et servent uniquement à illustrer le propos) :

[source,javascript]
----
const head = require('head');
const grep = require('stream-grep');
const fs = require('fs');

fs.createReadStream('/etc/networks')
  .pipe(head({ count: 3 }))
  .pipe(grep(/database/i))
  .pipe(process.stdout);
----

Cette manipulation équivaut à une transmission de pointeur de données.
Autrement dit, vous pouvez router un _stream_ vers plusieurs autres _streams_ sans pénaliser les ressources système !

[source,javascript]
.streams-multipipes.js
----
include::{sourceDir}/streams-multipipes.js[]
----

Tout comme dans notre exemple précédent `streams-jsonstream.js`, nous avons recours à l'évènement `data`.
Le module _JSONStream_ met temporairement en mémoire la structure de données parsée avant de l'émettre.

Mais cela empêche de _piper_ à nouveau.
Pour ce faire, il faut reconstituer un _stream_… tâche ardue mais simplifiée grâce au module _event-stream_ et à ses méthodes `map` et `mapSync`. +
Elles créent un nouveau _stream_ et écrivent dedans à chaque émission de l'évènement _data_ du _stream_ précédent.

On peut ainsi diriger notre _stream_ principal vers un fichier sur disque, mais aussi vers le parseur JSON qui lui aussi est dirigé vers le disque et la sortie standard :

[source,javascript]
.streams-multipipes-es.js
----
include::{sourceDir}/streams-multipipes-es.js[]
----

De nombreuses API Node exposent des _streams_ : requête HTTP, serveur HTTP, lecture et écriture de fichier, cryptographie, entrée/sortie standard du processus etc.

Pour être explicite : toute API vous permettra à un moment ou à un autre de manipuler des ensembles de données dont vous ne maitrisez pas la taille sans affecter les performances du système.
